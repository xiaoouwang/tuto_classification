{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing, metrics\n",
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frWac_skip = gensim.models.KeyedVectors.load_word2vec_format(\"frWac_no_postag_no_phrase_500_skip_cut100.bin\", binary=True, unicode_errors=\"ignore\")\n",
    "model_frWac = gensim.models.KeyedVectors.load_word2vec_format(\"frWac_no_postag_no_phrase_500_cbow_cut100.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'final1000.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"phrases\"] = df[\"text\"].apply(lambda x: \n",
    "          [sentence.strip() for sentence in x.split(\"\\n\") if sentence])\n",
    "df[\"tokens\"] = df[\"text\"].apply(lambda x: [token for token in x.replace(\"\\n\",\" \").split(\" \") if token])\n",
    "# create the corpus of phrases of 1000 articles\n",
    "liste_phrases_1000 = [y.split(\" \") for x in df[\"phrases\"].tolist() for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>phrases</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>economie</td>\n",
       "      <td>syndicat patronat entendre sauver retraite com...</td>\n",
       "      <td>[syndicat patronat entendre sauver retraite co...</td>\n",
       "      <td>[syndicat, patronat, entendre, sauver, retrait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economie</td>\n",
       "      <td>premier centrale nucléaire flottant monde rout...</td>\n",
       "      <td>[premier centrale nucléaire flottant monde rou...</td>\n",
       "      <td>[premier, centrale, nucléaire, flottant, monde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economie</td>\n",
       "      <td>Google Apple sceller rupture \\n\\nGoogle Apple ...</td>\n",
       "      <td>[Google Apple sceller rupture, Google Apple al...</td>\n",
       "      <td>[Google, Apple, sceller, rupture, Google, Appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economie</td>\n",
       "      <td>année exécrable marché emploi cadre \\n\\nmarché...</td>\n",
       "      <td>[année exécrable marché emploi cadre, marché t...</td>\n",
       "      <td>[année, exécrable, marché, emploi, cadre, marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economie</td>\n",
       "      <td>SoLocal ex-PagesJaunes conflit durcivre \\n\\nsi...</td>\n",
       "      <td>[SoLocal ex-PagesJaunes conflit durcivre, situ...</td>\n",
       "      <td>[SoLocal, ex-PagesJaunes, conflit, durcivre, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19395</th>\n",
       "      <td>politique</td>\n",
       "      <td>François Bayrou implacable procureur Nicolas S...</td>\n",
       "      <td>[François Bayrou implacable procureur Nicolas ...</td>\n",
       "      <td>[François, Bayrou, implacable, procureur, Nico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19396</th>\n",
       "      <td>politique</td>\n",
       "      <td>François Hollande plaider faveur nouveau instr...</td>\n",
       "      <td>[François Hollande plaider faveur nouveau inst...</td>\n",
       "      <td>[François, Hollande, plaider, faveur, nouveau,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19397</th>\n",
       "      <td>politique</td>\n",
       "      <td>Canard enchaîner Georges Tron louer bien appar...</td>\n",
       "      <td>[Canard enchaîner Georges Tron louer bien appa...</td>\n",
       "      <td>[Canard, enchaîner, Georges, Tron, louer, bien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19398</th>\n",
       "      <td>politique</td>\n",
       "      <td>sortie réussie Nicolas Sarkozy \\n\\nregarder fa...</td>\n",
       "      <td>[sortie réussie Nicolas Sarkozy, regarder fair...</td>\n",
       "      <td>[sortie, réussie, Nicolas, Sarkozy, regarder, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19399</th>\n",
       "      <td>politique</td>\n",
       "      <td>Pen Estrosi favorable référendum immigration \\...</td>\n",
       "      <td>[Pen Estrosi favorable référendum immigration,...</td>\n",
       "      <td>[Pen, Estrosi, favorable, référendum, immigrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               text  \\\n",
       "0       economie  syndicat patronat entendre sauver retraite com...   \n",
       "1       economie  premier centrale nucléaire flottant monde rout...   \n",
       "2       economie  Google Apple sceller rupture \\n\\nGoogle Apple ...   \n",
       "3       economie  année exécrable marché emploi cadre \\n\\nmarché...   \n",
       "4       economie  SoLocal ex-PagesJaunes conflit durcivre \\n\\nsi...   \n",
       "...          ...                                                ...   \n",
       "19395  politique  François Bayrou implacable procureur Nicolas S...   \n",
       "19396  politique  François Hollande plaider faveur nouveau instr...   \n",
       "19397  politique  Canard enchaîner Georges Tron louer bien appar...   \n",
       "19398  politique  sortie réussie Nicolas Sarkozy \\n\\nregarder fa...   \n",
       "19399  politique  Pen Estrosi favorable référendum immigration \\...   \n",
       "\n",
       "                                                 phrases  \\\n",
       "0      [syndicat patronat entendre sauver retraite co...   \n",
       "1      [premier centrale nucléaire flottant monde rou...   \n",
       "2      [Google Apple sceller rupture, Google Apple al...   \n",
       "3      [année exécrable marché emploi cadre, marché t...   \n",
       "4      [SoLocal ex-PagesJaunes conflit durcivre, situ...   \n",
       "...                                                  ...   \n",
       "19395  [François Bayrou implacable procureur Nicolas ...   \n",
       "19396  [François Hollande plaider faveur nouveau inst...   \n",
       "19397  [Canard enchaîner Georges Tron louer bien appa...   \n",
       "19398  [sortie réussie Nicolas Sarkozy, regarder fair...   \n",
       "19399  [Pen Estrosi favorable référendum immigration,...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [syndicat, patronat, entendre, sauver, retrait...  \n",
       "1      [premier, centrale, nucléaire, flottant, monde...  \n",
       "2      [Google, Apple, sceller, rupture, Google, Appl...  \n",
       "3      [année, exécrable, marché, emploi, cadre, marc...  \n",
       "4      [SoLocal, ex-PagesJaunes, conflit, durcivre, s...  \n",
       "...                                                  ...  \n",
       "19395  [François, Bayrou, implacable, procureur, Nico...  \n",
       "19396  [François, Hollande, plaider, faveur, nouveau,...  \n",
       "19397  [Canard, enchaîner, Georges, Tron, louer, bien...  \n",
       "19398  [sortie, réussie, Nicolas, Sarkozy, regarder, ...  \n",
       "19399  [Pen, Estrosi, favorable, référendum, immigrat...  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model_1000_100dim = Word2Vec(liste_phrases_1000)\n",
    "model_1000_200dim = Word2Vec(liste_phrases_1000,size = 200)\n",
    "model_1000_500dim = Word2Vec(liste_phrases_1000,size = 500)\n",
    "model_1000_1000dim = Word2Vec(liste_phrases_1000,size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1000_100dim.save(\"model_1000_100dim.model\")\n",
    "model_1000_200dim.save(\"model_1000_200dim.model\")\n",
    "model_1000_500dim.save(\"model_1000_500dim.model\")\n",
    "model_1000_1000dim.save(\"model_1000_1000dim.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the corpus of phrases of 8200 articles\n",
    "df_8200 = pd.read_pickle(r'final8200.pickle')\n",
    "df_8200[\"phrases\"] = df_8200[\"text\"].apply(lambda x: \n",
    "          [sentence.strip() for sentence in x.split(\"\\n\") if sentence])\n",
    "df_8200[\"tokens\"] = df_8200[\"text\"].apply(lambda x: [token for token in x.replace(\"\\n\",\" \").split(\" \") if token])\n",
    "liste_phrases_8200 = [y.split(\" \") for x in df_8200[\"phrases\"].tolist() for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8200_100dim = Word2Vec(liste_phrases_8200)\n",
    "model_8200_200dim = Word2Vec(liste_phrases_8200,size = 200)\n",
    "model_8200_500dim = Word2Vec(liste_phrases_8200,size = 500)\n",
    "model_8200_1000dim = Word2Vec(liste_phrases_8200,size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8200_100dim.save(\"model_8200_100dim.model\")\n",
    "model_8200_200dim.save(\"model_8200_200dim.model\")\n",
    "model_8200_500dim.save(\"model_8200_500dim.model\")\n",
    "model_8200_1000dim.save(\"model_8200_1000dim.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_count, default = 5\n",
    "model_8200_500dim_50cutoff = Word2Vec(liste_phrases_8200,size = 500, min_count = 50)\n",
    "model_8200_500dim_100cutoff = Word2Vec(liste_phrases_8200,size = 500,min_count = 100)\n",
    "model_8200_500dim_200cutoff = Word2Vec(liste_phrases_8200,size = 500,min_count = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8200_500dim_50cutoff.save(\"model_8200_500dim_50cutoff.model\")\n",
    "model_8200_500dim_100cutoff.save(\"model_8200_500dim_100cutoff.model\")\n",
    "model_8200_500dim_200cutoff.save(\"model_8200_500dim_200cutoff.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a wordvector model\n",
    "hehe = Word2Vec.load(\"model_8200_500dim_200cutoff.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croissance', 0.4628686010837555),\n",
       " ('productif', 0.4453972578048706),\n",
       " ('finance', 0.43670880794525146),\n",
       " ('relance', 0.4341583251953125),\n",
       " ('déséquilibre', 0.43389129638671875),\n",
       " ('transition', 0.4282788038253784),\n",
       " ('budget', 0.41785717010498047),\n",
       " ('industrie', 0.41529279947280884),\n",
       " ('cohésion', 0.4104558825492859),\n",
       " ('compétitivité', 0.4094610810279846)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hehe.most_similar(\"économie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(text,model):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    doc = [word for word in text if word in model.wv.vocab]\n",
    "    vector = np.mean(model[doc], axis=0)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def compare_categ_log(categories,df,model_vec,dim):\n",
    "    df_sampled = df[df['label'].isin(categories)]\n",
    "    ## split dataset\n",
    "    df_train, df_test = model_selection.train_test_split(df_sampled, test_size=0.3)\n",
    "    ## get target\n",
    "    y_train = df_train[\"label\"].values\n",
    "    y_test = df_test[\"label\"].values\n",
    "    df_train['doc_vector'] = df_train.tokens.apply(document_vector,model=model_vec)\n",
    "    df_test['doc_vector'] = df_test.tokens.apply(document_vector,model=model_vec)\n",
    "    train = df_train['doc_vector'].tolist()\n",
    "    test = df_test['doc_vector'].tolist()\n",
    "    clf = LogisticRegression().fit(train,y_train)\n",
    "    y_pred=clf.predict(test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(str(dim)+\" dimensions accuracy: \"+str(accuracy_score(y_test, y_pred)))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # classes = np.unique(y_test)\n",
    "    # sns.heatmap(cnf_matrix, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "    #             cbar=False)\n",
    "    # ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "    #     yticklabels=classes, title=\"Confusion matrix\")\n",
    "    # plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 dimensions accuracy: 0.8683333333333333\n",
      "200 dimensions accuracy: 0.8616666666666667\n",
      "500 dimensions accuracy: 0.8666666666666667\n",
      "1000 dimensions accuracy: 0.8566666666666667\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log([\"economie\",\"politique\"],df,model_1000_100dim,100)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_1000_200dim,200)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_1000_500dim,500)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_1000_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 dimensions accuracy: 0.9233333333333333\n",
      "200 dimensions accuracy: 0.925\n",
      "500 dimensions accuracy: 0.905\n",
      "1000 dimensions accuracy: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_100dim,100)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_200dim,200)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_500dim,500)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff 500dim\n",
      "100 dimensions accuracy: 0.9283333333333333\n",
      "200 dimensions accuracy: 0.93\n",
      "500 dimensions accuracy: 0.9283333333333333\n",
      "1000 dimensions accuracy: 0.9383333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"cutoff 500dim\") # amelioration vs 0.905\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_500dim,100)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_500dim_50cutoff,200)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_500dim_100cutoff,500)\n",
    "compare_categ_log([\"economie\",\"politique\"],df,model_8200_500dim_200cutoff,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modele 1000 articles\n",
      "100 dimensions accuracy: 0.825\n",
      "200 dimensions accuracy: 0.8083333333333333\n",
      "500 dimensions accuracy: 0.8116666666666666\n",
      "1000 dimensions accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "print(\"modele 1000 articles\")\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_1000_100dim,100)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_1000_200dim,200)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_1000_500dim,500)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_1000_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modele 8200 articles\n",
      "100 dimensions accuracy: 0.905\n",
      "200 dimensions accuracy: 0.9166666666666666\n",
      "500 dimensions accuracy: 0.9166666666666666\n",
      "1000 dimensions accuracy: 0.9083333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"modele 8200 articles\")\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_100dim,100)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_200dim,200)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_500dim,500)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff 500dim\n",
      "100 dimensions accuracy: 0.9166666666666666\n",
      "200 dimensions accuracy: 0.9083333333333333\n",
      "500 dimensions accuracy: 0.9133333333333333\n",
      "1000 dimensions accuracy: 0.9116666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"cutoff 500dim\")  # no amelioration vs 0.91\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_500dim,100)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_500dim_50cutoff,200)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_500dim_100cutoff,500)\n",
    "compare_categ_log([\"economie\",\"societe\"],df,model_8200_500dim_200cutoff,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 dimensions accuracy: 0.8216666666666667\n",
      "200 dimensions accuracy: 0.7833333333333333\n",
      "500 dimensions accuracy: 0.83\n",
      "1000 dimensions accuracy: 0.785\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log([\"politique\",\"societe\"],df,model_1000_100dim,100)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_1000_200dim,200)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_1000_500dim,500)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_1000_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff 500dim\n",
      "100 dimensions accuracy: 0.8416666666666667\n",
      "200 dimensions accuracy: 0.8383333333333334\n",
      "500 dimensions accuracy: 0.8283333333333334\n",
      "1000 dimensions accuracy: 0.8316666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"cutoff 500dim\") # amelioration vs 0.81, see below\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_500dim,100)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_500dim_50cutoff,200)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_500dim_100cutoff,500)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_500dim_200cutoff,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 dimensions accuracy: 0.8366666666666667\n",
      "200 dimensions accuracy: 0.84\n",
      "500 dimensions accuracy: 0.8133333333333334\n",
      "1000 dimensions accuracy: 0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_100dim,100)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_200dim,200)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_500dim,500)\n",
    "compare_categ_log([\"politique\",\"societe\"],df,model_8200_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 dimensions accuracy: 0.7211111111111111\n",
      "200 dimensions accuracy: 0.7177777777777777\n",
      "500 dimensions accuracy: 0.7366666666666667\n",
      "1000 dimensions accuracy: 0.7133333333333334\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_1000_100dim,100)\n",
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_1000_200dim,200)\n",
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_1000_200dim,500)\n",
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_1000_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 dimensions accuracy: 0.8066666666666666\n",
      "200 dimensions accuracy: 0.7888888888888889\n",
      "500 dimensions accuracy: 0.8077777777777778\n",
      "1000 dimensions accuracy: 0.8188888888888889\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_8200_100dim,100)\n",
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_8200_200dim,200)\n",
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_8200_200dim,500)\n",
    "compare_categ_log([\"politique\",\"societe\",\"economie\"],df,model_8200_1000dim,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('santé', 0.812455415725708),\n",
       " ('transition', 0.8102002739906311),\n",
       " ('budget', 0.7560843229293823),\n",
       " ('enseignement', 0.7560242414474487),\n",
       " ('finance', 0.7490084767341614),\n",
       " ('ex-premier', 0.7483202219009399),\n",
       " ('immigration', 0.7432029247283936),\n",
       " ('intérieur', 0.743035614490509),\n",
       " ('culture', 0.7387093305587769),\n",
       " ('Pellerin', 0.7344215512275696)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1000_100dim.most_similar(\"économie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croissance', 0.5927355885505676),\n",
       " ('finance', 0.5501879453659058),\n",
       " ('compétitivité', 0.5379248261451721),\n",
       " ('productif', 0.5106614828109741),\n",
       " ('relance', 0.5067898035049438),\n",
       " ('budget', 0.5056710839271545),\n",
       " ('économique', 0.49872809648513794),\n",
       " ('déséquilibre', 0.47295713424682617),\n",
       " ('structurel', 0.47245392203330994),\n",
       " ('budgétaire', 0.47141095995903015)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8200_100dim.most_similar(\"économie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "def compare_categ_log_1vsall(categories,df,model_vec):\n",
    "    df_sampled = df[df.label.isin(categories)]\n",
    "    df_train, df_test = model_selection.train_test_split(df_sampled, test_size=0.3)\n",
    "    ## get target\n",
    "    y_train = df_train[\"label\"].values\n",
    "    y_test = df_test[\"label\"].values\n",
    "    df_train['doc_vector'] = df_train.tokens.apply(document_vector,model=model_vec)\n",
    "    df_test['doc_vector'] = df_test.tokens.apply(document_vector,model=model_vec)\n",
    "    train = df_train['doc_vector'].tolist()\n",
    "    test = df_test['doc_vector'].tolist()\n",
    "    clf = OneVsRestClassifier(SVC()).fit(train, y_train)\n",
    "    y_pred=clf.predict(test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(cnf_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # classes = np.unique(y_test)\n",
    "    # sns.heatmap(cnf_matrix, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "    #             cbar=False)\n",
    "    # ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "    #     yticklabels=classes, title=\"Confusion matrix\")\n",
    "    # plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[244  25  36]\n",
      " [ 28 228  36]\n",
      " [ 47  62 194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.76      0.80      0.78       305\n",
      "   politique       0.72      0.78      0.75       292\n",
      "     societe       0.73      0.64      0.68       303\n",
      "\n",
      "    accuracy                           0.74       900\n",
      "   macro avg       0.74      0.74      0.74       900\n",
      "weighted avg       0.74      0.74      0.74       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_1vsall([\"politique\",\"societe\",\"economie\"],df,model_1000_100dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[280  20  14]\n",
      " [ 18 234  29]\n",
      " [ 25  53 227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.87      0.89      0.88       314\n",
      "   politique       0.76      0.83      0.80       281\n",
      "     societe       0.84      0.74      0.79       305\n",
      "\n",
      "    accuracy                           0.82       900\n",
      "   macro avg       0.82      0.82      0.82       900\n",
      "weighted avg       0.83      0.82      0.82       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_1vsall([\"politique\",\"societe\",\"economie\"],df,model_8200_100dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260  21  17]\n",
      " [ 22 245  30]\n",
      " [ 24  53 228]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.85      0.87      0.86       298\n",
      "   politique       0.77      0.82      0.80       297\n",
      "     societe       0.83      0.75      0.79       305\n",
      "\n",
      "    accuracy                           0.81       900\n",
      "   macro avg       0.82      0.81      0.81       900\n",
      "weighted avg       0.82      0.81      0.81       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_1vsall([\"politique\",\"societe\",\"economie\"],df,model_frWac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  14  13]\n",
      " [ 24 250  50]\n",
      " [ 25  52 213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.84      0.91      0.87       286\n",
      "   politique       0.79      0.77      0.78       324\n",
      "     societe       0.77      0.73      0.75       290\n",
      "\n",
      "    accuracy                           0.80       900\n",
      "   macro avg       0.80      0.80      0.80       900\n",
      "weighted avg       0.80      0.80      0.80       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_1vsall([\"politique\",\"societe\",\"economie\"],df,model_frWac_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def compare_categ_log_knearest(categories,df,model_vec,nb_neighbor):\n",
    "    df_sampled = df[df.label.isin(categories)]\n",
    "    # print(df_sampled)\n",
    "    ## split dataset\n",
    "    df_train, df_test = model_selection.train_test_split(df_sampled, test_size=0.3)\n",
    "    ## get target\n",
    "    y_train = df_train[\"label\"].values\n",
    "    y_test = df_test[\"label\"].values\n",
    "    df_train['doc_vector'] = df_train.tokens.apply(document_vector,model=model_vec)\n",
    "    df_test['doc_vector'] = df_test.tokens.apply(document_vector,model=model_vec)\n",
    "    train = df_train['doc_vector'].tolist()\n",
    "    test = df_test['doc_vector'].tolist()\n",
    "    clf = KNeighborsClassifier(n_neighbors=nb_neighbor)\n",
    "    clf.fit(train, y_train)\n",
    "    y_pred=clf.predict(test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(cnf_matrix)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # classes = np.unique(y_test)\n",
    "    # sns.heatmap(cnf_matrix, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "    #             cbar=False)\n",
    "    # ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "    #     yticklabels=classes, title=\"Confusion matrix\")\n",
    "    # plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[224  31  38]\n",
      " [ 45 180  75]\n",
      " [ 68  71 168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.66      0.76      0.71       293\n",
      "   politique       0.64      0.60      0.62       300\n",
      "     societe       0.60      0.55      0.57       307\n",
      "\n",
      "    accuracy                           0.64       900\n",
      "   macro avg       0.63      0.64      0.63       900\n",
      "weighted avg       0.63      0.64      0.63       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_knearest([\"politique\",\"societe\",\"economie\"],df,model_1000_100dim,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[241   9  34]\n",
      " [ 44 219  48]\n",
      " [ 59  63 183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.70      0.85      0.77       284\n",
      "   politique       0.75      0.70      0.73       311\n",
      "     societe       0.69      0.60      0.64       305\n",
      "\n",
      "    accuracy                           0.71       900\n",
      "   macro avg       0.71      0.72      0.71       900\n",
      "weighted avg       0.72      0.71      0.71       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_knearest([\"politique\",\"societe\",\"economie\"],df,model_1000_100dim,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239  24  21]\n",
      " [ 21 233  60]\n",
      " [ 29  61 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.83      0.84      0.83       284\n",
      "   politique       0.73      0.74      0.74       314\n",
      "     societe       0.72      0.70      0.71       302\n",
      "\n",
      "    accuracy                           0.76       900\n",
      "   macro avg       0.76      0.76      0.76       900\n",
      "weighted avg       0.76      0.76      0.76       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_knearest([\"politique\",\"societe\",\"economie\"],df,model_8200_100dim,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[252  19  14]\n",
      " [ 18 261  25]\n",
      " [ 33  68 210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.83      0.88      0.86       285\n",
      "   politique       0.75      0.86      0.80       304\n",
      "     societe       0.84      0.68      0.75       311\n",
      "\n",
      "    accuracy                           0.80       900\n",
      "   macro avg       0.81      0.81      0.80       900\n",
      "weighted avg       0.81      0.80      0.80       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_knearest([\"politique\",\"societe\",\"economie\"],df,model_8200_100dim,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235  40  27]\n",
      " [ 29 221  39]\n",
      " [ 23  88 198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.82      0.78      0.80       302\n",
      "   politique       0.63      0.76      0.69       289\n",
      "     societe       0.75      0.64      0.69       309\n",
      "\n",
      "    accuracy                           0.73       900\n",
      "   macro avg       0.73      0.73      0.73       900\n",
      "weighted avg       0.74      0.73      0.73       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_knearest([\"politique\",\"societe\",\"economie\"],df,model_frWac,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[301  26  11]\n",
      " [ 23 247  21]\n",
      " [ 27  75 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economie       0.86      0.89      0.87       338\n",
      "   politique       0.71      0.85      0.77       291\n",
      "     societe       0.84      0.62      0.72       271\n",
      "\n",
      "    accuracy                           0.80       900\n",
      "   macro avg       0.80      0.79      0.79       900\n",
      "weighted avg       0.80      0.80      0.79       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_categ_log_knearest([\"politique\",\"societe\",\"economie\"],df,model_frWac,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "def compare_categ_multiperceptron(categories,df,model_vec):\n",
    "    df_sampled = df[df.label.isin(categories)]\n",
    "    # print(df_sampled)\n",
    "    ## split dataset\n",
    "    df_train, df_test = model_selection.train_test_split(df_sampled, test_size=0.3)\n",
    "    ## get target\n",
    "    y_train = df_train[\"label\"].values\n",
    "    y_test = df_test[\"label\"].values\n",
    "    df_train['doc_vector'] = df_train.tokens.apply(document_vector,model=model_vec)\n",
    "    df_test['doc_vector'] = df_test.tokens.apply(document_vector,model=model_vec)\n",
    "    train = df_train['doc_vector'].tolist()\n",
    "    test = df_test['doc_vector'].tolist()\n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(train, y_train)\n",
    "    y_pred=clf.predict(test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print10\" dimensions accuracy: \"+str(accuracy_score(y_test, y_pred)))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    print(cnf_matrix)\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # classes = np.unique(y_test)\n",
    "    # sns.heatmap(cnf_matrix, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "    #             cbar=False)\n",
    "    # ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "    #     yticklabels=classes, title=\"Confusion matrix\")\n",
    "    # plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimensions accuracy: 0.7588888888888888\n",
      "[[251  25  29]\n",
      " [ 33 225  36]\n",
      " [ 38  56 207]]\n"
     ]
    }
   ],
   "source": [
    "compare_categ_multiperceptron([\"politique\",\"societe\",\"economie\"],df,model_1000_100dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimensions accuracy: 0.7966666666666666\n",
      "[[267  26  21]\n",
      " [ 14 234  49]\n",
      " [ 20  53 216]]\n"
     ]
    }
   ],
   "source": [
    "compare_categ_multiperceptron([\"politique\",\"societe\",\"economie\"],df,model_8200_100dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimensions accuracy: 0.8088888888888889\n",
      "[[257  23  24]\n",
      " [ 17 221  50]\n",
      " [ 18  40 250]]\n"
     ]
    }
   ],
   "source": [
    "compare_categ_multiperceptron([\"politique\",\"societe\",\"economie\"],df,model_8200_500dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimensions accuracy: 0.7977777777777778\n",
      "[[252  23  23]\n",
      " [ 16 240  44]\n",
      " [ 28  48 226]]\n"
     ]
    }
   ],
   "source": [
    "compare_categ_multiperceptron([\"politique\",\"societe\",\"economie\"],df,model_8200_1000dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimensions accuracy: 0.81\n",
      "[[265  23  19]\n",
      " [ 19 236  45]\n",
      " [ 15  50 228]]\n"
     ]
    }
   ],
   "source": [
    "compare_categ_multiperceptron([\"politique\",\"societe\",\"economie\"],df,model_frWac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimensions accuracy: 0.8\n",
      "[[256  21  20]\n",
      " [ 17 258  25]\n",
      " [ 21  76 206]]\n"
     ]
    }
   ],
   "source": [
    "compare_categ_multiperceptron([\"politique\",\"societe\",\"economie\"],df,model_frWac_skip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
